{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using Selenium and Requests: _Fjall Raven & Rains_\n",
    "\n",
    "In this section we will be using selenium and beautiful soup to scrape all of the women's bags from Fjall Raven & Rains. First, we will use selenium to get everylink for the bags, and then use Beautiful Soup to get the correct picture,price, product link, and description.\n",
    "\n",
    "We have linked some great resources in our other notebooks.\n",
    "\n",
    "#### Import your needed Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create variables for each of the URL\n",
    "\n",
    "We will do this for each of the pages we will be pulling from on _Fjall Raven & Rains_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fjall_raven = 'https://www.fjallraven.us/collections/backpacks'\n",
    "rains = 'https://www.us.rains.com/collections/backpacks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rains:\n",
    "\n",
    "We will start with Rains, grabbing all of their bags with every colors. The name of the picture files, the prices and the names of the items will be saved in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get(rains)\n",
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "class_1 = 'flexslider collection'\n",
    "class_2 = 'details_outer'\n",
    "divs_imgs = soup.findAll('div', {'class':class_1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting, we can tell that these are all of the bags on the page. However, let's drop item 14 as it is not a bookbag. In the list comprehension we use [::2] to skip everyother item in the list of images for each item. These are the hover images which we do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [x.findAll('img')[::2] for x in divs_imgs]\n",
    "del images[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_imgs = [img for img_li in images for img in img_li]\n",
    "\n",
    "rains_colors = [x['alt'] for x in flat_imgs]\n",
    "rains_urls = ['https:' + x['data-src'] for x in flat_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divs = soup.findAll('div', {'class':class_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = [x.find('a')['title'] for x in divs]\n",
    "pri = [x.find('a').find('span',{'class':'price_lg'}).text.replace('\\n','').strip() for x in divs]\n",
    "prices = [float(x.replace(' USD','').replace('$','')) for x in pri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del name[13]\n",
    "del prices[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "div_num = [len(i) for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_count = []\n",
    "prices_count = []\n",
    "for i in range(0,len(div_num)):\n",
    "    name_count.append([name[i]]*div_num[i])\n",
    "    prices_count.append([prices[i]]*div_num[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_rains = [name for name_li in name_count for name in name_li]\n",
    "prices_rains = [price for price_li in prices_count for price in price_li]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame and create a function to download pictures :\n",
    "\n",
    "Below we will use the lists created above and make a dataframe. Then we will define a function to download the images into our directory, and save the image file name in a new column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = [names_rains,prices_rains,rains_colors,rains_urls]\n",
    "rains_df = pd.DataFrame(table).transpose()\n",
    "rains_df.rename( columns={0:'Names', 1: 'Prices',2:'Color',3:'URL'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rains_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_src_image_apply(company,short,url):\n",
    "    start_time = time.time()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        global c\n",
    "        c += 1\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        image_save_loc = company+short+'_'+str(c)+'.jpg'\n",
    "        img.save(image_save_loc, \"JPEG\")\n",
    "        print(\"Saved \"+short+\"_{}\".format(c)+\".jpg\")\n",
    "        return short+\"_\"+ str(c)+\".jpg\"\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save all images using an apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "rains_df['img'] = rains_df.URL.apply(lambda x: save_src_image_apply('../../Rains_backpacks/','rains_',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rains_df.to_csv('../../rains_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fjall Raven\n",
    "\n",
    "Repeat earlier steps for Fjall Raven backpacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_2 = requests.get(fjall_raven)\n",
    "soup_2 = BeautifulSoup(page_2.content, 'lxml')\n",
    "item_class = 'grid-view-item__link'\n",
    "divs_items = soup_2.findAll('div', {'class':item_class})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables to store the class names for each of the itmes that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thumb_class ='product-single__thumbnails'\n",
    "title_class = 'h4 grid-view-item__title'\n",
    "price_class = 'h4 grid-view-item__price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these classes in __list comprehensions__ to loop through the list of divs and further filter the items we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_FR = [x.find('div', {'class':title_class}).text for x in divs_items]\n",
    "prices_FR = [x.find('div',{'class':price_class}).text for x in divs_items]\n",
    "links = ['https://www.fjallraven.us/'+x.find('a')['href'] for x in divs_items]\n",
    "colors_divs = [x.find('select').findAll('option') for x in divs_items]\n",
    "colors_FR = [[x.text.replace('\\n','').strip() for x in i]for i in colors_divs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use each link to grab the images for each color bag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del names_FR[20]\n",
    "del prices_FR[20]\n",
    "del links[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_FR = []\n",
    "skips = [2,2,1,1,2,2,1,1,1,1,1,1,1,1,1,1,1,4,3,3,1,1]\n",
    "for i,link in enumerate(links):\n",
    "    loop_page = requests.get(link)\n",
    "    soup_loop = BeautifulSoup(loop_page.content, 'lxml')\n",
    "    img_list = soup_loop.find('ul',{'class':thumb_class})\n",
    "    img_items = img_list.findAll('a')[::skips[i]]\n",
    "    imgs_FR.append(['https:'+x['data-zoom'] for x in img_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lengths of color and image lists for each item to make price and name lists long enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_FR_count = []\n",
    "names_FR_count = []\n",
    "for i in range(0,len(names_FR)):\n",
    "    names_FR_count.append([names_FR[i]]*len(imgs_FR[i]))\n",
    "    price_FR_count.append([prices_FR[i]]*len(imgs_FR[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten all lists from list of lists to just a single list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_fjall = [name for name_li in names_FR_count for name in name_li]\n",
    "prices_fjall = [price for price_li in price_FR_count for price in price_li]\n",
    "colors_fjall = [color for color_li in colors_FR for color in color_li]\n",
    "imgs_fjall = [img for imgs_li in imgs_FR for img in imgs_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_FR = [names_fjall,prices_fjall,imgs_fjall]\n",
    "fjallraven_df = pd.DataFrame(table_FR).transpose()\n",
    "fjallraven_df.rename( columns={0:'Names', 1: 'Prices',2:'URL'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fjallraven_df.Prices = fjallraven_df.Prices.apply(lambda x: float(x.replace('$','')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save images and file names:\n",
    "\n",
    "Use function from before to save images and create the column with the file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "fjallraven_df['img'] = fjallraven_df.URL.apply(lambda x: save_src_image_apply('../../fjall_raven_2/','FJ_',x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bad_bags = ['FJ__17.jpg','FJ__18.jpg','FJ__29.jpg','FJ__53.jpg',\n",
    "#            'FJ__54.jpg','FJ__55.jpg','FJ__56.jpg','FJ__57.jpg','FJ__58.jpg',\n",
    "#            'FJ__59.jpg','FJ__60.jpg','FJ__61.jpg','FJ__62.jpg','FJ__63.jpg','FJ__64.jpg'\n",
    "#            'FJ__65.jpg','FJ__66.jpg','FJ__67.jpg','FJ__68.jpg','FJ__69.jpg',\n",
    "#            'FJ__70.jpg','FJ__78.jpg','FJ__83.jpg','FJ__84.jpg','FJ__85.jpg',\n",
    "#            'FJ__104.jpg','FJ__107.jpg','FJ__108.jpg','FJ__111.jpg',\n",
    "#            'FJ__112.jpg','FJ__114.jpg','FJ__115.jpg','FJ__117.jpg','FJ__118.jpg',\n",
    "#            'FJ__120.jpg','FJ__121.jpg','FJ__127.jpg','FJ__137.jpg','FJ__145.jpg','FJ__151.jpg',\n",
    "#             'FJ__152.jpg','FJ__153.jpg','FJ__157.jpg','FJ__158.jpg','FJ__159.jpg'\n",
    "#            'FJ__161.jpg','FJ__162.jpg','FJ__163.jpg','FJ__164.jpg','FJ__165.jpg','FJ__166.jpg']\n",
    "\n",
    "# fjallraven_df_test = fjallraven_df[fjallraven_df.img.apply(lambda x: x not in bad_bags)]\n",
    "fjallraven_df_test.to_csv('../../fjallraven_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fjall Raven #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fjallrave_2 = 'https://www.fjallraven.us/collections/kanken?page=1&sort_by=price-descending'\n",
    "page_3 = requests.get(fjallrave_2)\n",
    "soup_3 = BeautifulSoup(page_3.content, 'lxml')\n",
    "item_class = 'grid-view-item__link'\n",
    "divs_items_2 = soup_3.findAll('div', {'class':item_class})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part our code to grab these images will not change. However, we will be adding a try-except. Some of the bags only have one picture and therefore do not have the same classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_FR_2 = [x.find('div', {'class':title_class}).text for x in divs_items_2]\n",
    "prices_FR_2 = [x.find('div',{'class':price_class}).text for x in divs_items_2]\n",
    "links_2 = ['https://www.fjallraven.us/'+x.find('a')['href'] for x in divs_items_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_FR_2 = []\n",
    "single_photo = 'product-single__photos'\n",
    "skips_2 = [10,10,1,4,1,3,1,2,2,1,2,1,2,1,1,1,1,2,1,2,1,1,2]\n",
    "for i,link in enumerate(links_2):\n",
    "    loop_page = requests.get(link)\n",
    "    soup_loop = BeautifulSoup(loop_page.content, 'lxml')\n",
    "    try:\n",
    "        img_list = soup_loop.find('ul',{'class':thumb_class})\n",
    "        img_items = img_list.findAll('a')[::skips_2[i]]\n",
    "        imgs_FR_2.append(['https:'+x['data-zoom'] for x in img_items])\n",
    "    except:\n",
    "        img_list = soup_loop.find('div',{'class':single_photo})\n",
    "        img_items = img_list.findAll('img')\n",
    "        imgs_FR_2.append(['https:'+x['src'] for x in img_items])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_FR_count_2 = []\n",
    "names_FR_count_2 = []\n",
    "for i in range(0,len(names_FR_2)):\n",
    "    names_FR_count_2.append([names_FR_2[i]]*len(imgs_FR_2[i]))\n",
    "    price_FR_count_2.append([prices_FR_2[i]]*len(imgs_FR_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_fjall_2 = [name for name_li in names_FR_count_2 for name in name_li]\n",
    "prices_fjall_2 = [price for price_li in price_FR_count_2 for price in price_li]\n",
    "imgs_fjall_2 = [img for imgs_li in imgs_FR_2 for img in imgs_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_FR_2 = [names_fjall_2,prices_fjall_2,imgs_fjall_2]\n",
    "fjallraven_df_2 = pd.DataFrame(table_FR_2).transpose()\n",
    "fjallraven_df_2.rename( columns={0:'Names', 1: 'Prices',2:'URL'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjallraven_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fjallraven_df_2.Prices = fjallraven_df_2.Prices.apply(lambda x: float(x.replace('$','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 166\n",
    "fjallraven_df_2['img'] = fjallraven_df_2.URL.apply(lambda x: save_src_image_apply('../../fjall_raven_2/','FJ_',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_bags_2 = ['FJ__177','FJ__178','FJ__179','FJ__180','FJ__181','FJ__182','FJ__183',\n",
    "              'FJ__184','FJ__185','FJ__186','FJ__187','FJ__188','FJ__189','FJ__190',\n",
    "              'FJ__191','FJ__192','FJ__193','FJ__194','FJ__195','FJ__196','FJ__197',\n",
    "              'FJ__198','FJ__199','FJ__200','FJ__201','FJ__202','FJ__204','FJ__205',\n",
    "              'FJ__206','FJ__207','FJ__208','FJ__209','FJ__210','FJ__211','FJ__234',\n",
    "              'FJ__235','FJ__259','FJ__260','FJ__261','FJ__278','FJ__279','FJ__280',\n",
    "              'FJ__296','FJ__297','FJ__298','FJ__314','FJ__315','FJ__316','FJ__317',\n",
    "              'FJ__323','FJ__325','FJ__327','FJ__329','FJ__332','FJ__339','FJ__341',\n",
    "              'FJ__343','FJ__345','FJ__348']\n",
    "\n",
    "fjallraven_df_2 = fjallraven_df_2[fjallraven_df_2.img.apply(lambda x: x not in bad_bags_2)]\n",
    "fjallraven_df_2.to_csv('../../fjallraven_df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([fjallraven_df_test,fjallraven_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('../../fjallraven_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['brand'] = 'Fjallraven'\n",
    "result['source'] = 'Fjallraven'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
