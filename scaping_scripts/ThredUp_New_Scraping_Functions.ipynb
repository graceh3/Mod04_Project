{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totesurls=[]\n",
    "totesurls=['https://www.thredup.com/products/handbags/totes?department_tags=handbags&search_tags=women-handbags%2Cwomen-handbags-totes']\n",
    "\n",
    "# loop through to get url for each page\n",
    "for n in range(2, 98):\n",
    "    totesurls.append(f'https://www.thredup.com/products/handbags/totes?department_tags=handbags&search_tags=women-handbags%2Cwomen-handbags-totes&page={n}')\n",
    "    \n",
    "# check number of urls collected\n",
    "len(totesurls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WORKS ONLY FOR THREDUP URLS ###\n",
    "# helper function to get bag info and locally save bag images\n",
    "def get_bag_info(url, bag_type, img_directory, counter_start, is_ethical, source):\n",
    "    '''\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    - url : str format of page url\n",
    "    - bag_type : str format of bag type\n",
    "    - img_directory : str format of local directory for saved images\n",
    "    - counter_start : int counter start value for file naming convention\n",
    "    - is_ethical : int/boolean whether source is ethical or not\n",
    "    - source : str format of website source\n",
    "\n",
    "    OUTPUT\n",
    "    ----------\n",
    "    - dataframe containing bag details\n",
    "    - dictionary containing bag details\n",
    "    - images saved locally to specified img_directory\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html5lib')\n",
    "\n",
    "    # find all bag data in html for given url\n",
    "    bags = soup.find_all('div', {'class': 'uiUj-TxKXzmIOHZu6poxM'})\n",
    "\n",
    "    # initiate lists of data to acquire\n",
    "    bag_names = []\n",
    "    bag_brands = []\n",
    "    bag_prices = []\n",
    "    bag_urls = []\n",
    "    bag_image_urls = []\n",
    "    bag_img_fnames = []\n",
    "    bag_descs=[]\n",
    "    \n",
    "    # loop through class tags to get each bag info\n",
    "    for i, b in enumerate(bags):\n",
    "        bag_names.append(b.find('div', {'class': '_138U7gqcrSxaloaCpyMPZg'}).text)\n",
    "        bag_brands.append(b.find('h3', {'class': '_7hDjEshDdTGEs_hDVNnib'}).text)\n",
    "        bag_prices.append(b.find('b').text)\n",
    "        bag_urls.append(f'https://www.thredup.com'+b.find('a').attrs['href'])\n",
    "    # go into each bag url and get large bag image url\n",
    "    \n",
    "    print(f'Getting bag image URLs')\n",
    "    for i, url in enumerate(bag_urls):\n",
    "        print(f'{i+1}/{len(bag_urls)}')\n",
    "        soup = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "        for img in soup.findAll('img'):\n",
    "            if 'large' in img.attrs['src']:\n",
    "                bag_image_urls.append(img.attrs['src'])\n",
    "        # get bag descriptions\n",
    "        single_desc=[]\n",
    "        if len(soup.find('ul', {'class':'list-disc'}).findAll('li'))>0:\n",
    "            for item in soup.find('ul', {'class':'list-disc'}).findAll('li'):\n",
    "                single_desc.append(item.text)\n",
    "        else:\n",
    "            single_desc.append('None')\n",
    "        bag_descs.append(single_desc)\n",
    "        time.sleep(0.25)\n",
    "\n",
    "    # format bag data into a dictionary\n",
    "    all_data = {'bag_name': bag_names,\n",
    "                'brand': bag_brands,\n",
    "                'price': bag_prices,\n",
    "                'bag_url': bag_urls,\n",
    "                'img_url': bag_image_urls,\n",
    "                'img_filename': bag_img_fnames,\n",
    "                'bag_desc': bag_descs}\n",
    "    \n",
    "    # make sure you have same number of image urls and bag names\n",
    "    if len(bag_image_urls) == len(bag_names):\n",
    "        # save bag images to local direcotry\n",
    "        print(f'Saving images to {img_directory}.')\n",
    "        for i, url in enumerate(bag_image_urls):\n",
    "            brandname = bag_brands[i].strip().replace(' ', '')[:3].lower()\n",
    "            fname = f'thredup_{brandname}_{counter_start+i}.png'\n",
    "            file_name = f'{img_directory}/{fname}'\n",
    "            urllib.request.urlretrieve(url, file_name)\n",
    "            bag_img_fnames.append(fname)\n",
    "\n",
    "        # convert dictionary to dataframe\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df['type'] = bag_type  # adding bag type to all items in dataframe\n",
    "        df['is_ethical'] = is_ethical  # boolean value (1 = yes, 0 = no)\n",
    "        df['source'] = source\n",
    "\n",
    "        print(f'Bag images have been saved to {img_directory}.')\n",
    "        return df, all_data\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On url: 1/1\n",
      "Getting bag image URLs\n",
      "1/50\n",
      "2/50\n",
      "3/50\n",
      "4/50\n",
      "5/50\n",
      "6/50\n",
      "7/50\n",
      "8/50\n",
      "9/50\n",
      "10/50\n",
      "11/50\n",
      "12/50\n",
      "13/50\n",
      "14/50\n",
      "15/50\n",
      "16/50\n",
      "17/50\n",
      "18/50\n",
      "19/50\n",
      "20/50\n",
      "21/50\n",
      "22/50\n",
      "23/50\n",
      "24/50\n",
      "25/50\n",
      "26/50\n",
      "27/50\n",
      "28/50\n",
      "29/50\n",
      "30/50\n",
      "31/50\n",
      "32/50\n",
      "33/50\n",
      "34/50\n",
      "35/50\n",
      "36/50\n",
      "37/50\n",
      "38/50\n",
      "39/50\n",
      "40/50\n",
      "41/50\n",
      "42/50\n",
      "43/50\n",
      "44/50\n",
      "45/50\n",
      "46/50\n",
      "47/50\n",
      "48/50\n",
      "49/50\n",
      "50/50\n",
      "Saving images to C:/Users/Grace/Documents/goodtwin_local/img_new/new_ethical/Totes.\n",
      "Skipping: 1/1\n"
     ]
    }
   ],
   "source": [
    "# using helper function get_bag_info, loop through a portion of urls to get bag information & locally save bag image\n",
    "counter = 0\n",
    "df_all_totes = pd.DataFrame()\n",
    "for i, url in enumerate(totesurls[:1]):\n",
    "    try:\n",
    "        print(f'On url: {i+1}/{len(totesurls[:1])}')\n",
    "        df, dict_ = get_bag_info(url, 'Totes', 'C:/Users/Grace/Documents/goodtwin_local/img_new/new_ethical/Totes', counter, 1, 'thredup')\n",
    "        counter += len(df)\n",
    "        df_all_totes = df_all_totes.append(df, ignore_index=True)\n",
    "    except:\n",
    "        print(f'Skipping: {i+1}/{len(totesurls[:1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
